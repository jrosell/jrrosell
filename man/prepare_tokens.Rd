% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/text.R
\name{prepare_tokens}
\alias{prepare_tokens}
\title{Prepare tokens from text for Analysis}
\usage{
prepare_tokens(
  text,
  stopwords = NULL,
  lang = "spanish",
  sep = "\\\\s+",
  remove_digits = TRUE,
  remove_accents = TRUE,
  lemmatize = c("none", "udpipe", "spacyr"),
  model_dir = getwd()
)
}
\arguments{
\item{text}{A character vector or object that can be coerced to a character string. Represents the input text to be cleaned.}

\item{stopwords}{A character vector specifying stopwords removal. Defaults tm:stopwords package.}

\item{lang}{defaults to \code{"spanish"}}

\item{sep}{separator for spliting defaults to \code{"\\\\s+"}}

\item{remove_digits}{= TRUE}

\item{remove_accents}{= TRUE}

\item{lemmatize}{= c("none", "udpipe", "spacyr") defaults to \code{"none"}}

\item{model_dir}{defaults to getwd()}
}
\value{
A cleaned character vector, with stopwords removed and text formatted for analysis and can be lemmatized optionally and then returns a character vector of lemmas.
}
\description{
This function processes a given text string by converting it to lowercase, removing numbers,
non-alphanumeric characters, extra whitespace, and stopwords based on a specified language.
It also transliterates text to ASCII, splits words, and reconstructs a clean text string suitable for analysis.
}
\examples{
# Example usage:
prepare_tokens("Â¡Hola! Esto es una prueba 123.", lemmatize = "none")

}
\keyword{text}
